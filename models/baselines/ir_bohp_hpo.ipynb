{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires Python 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_rate': 0.47931986744102967, 'lr': 8.982041368038431e-06, 'num_conv_layers': 1, 'num_fc_units': 46, 'num_filters_1': 5, 'optimizer': 'SGD', 'sgd_momentum': 0.7712909010814899}\n",
      "WARNING:tensorflow:From /home/francisco/miniconda3/envs/tests-gpu-py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/francisco/miniconda3/envs/tests-gpu-py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/francisco/miniconda3/envs/tests-gpu-py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/francisco/miniconda3/envs/tests-gpu-py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/francisco/miniconda3/envs/tests-gpu-py3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/francisco/miniconda3/envs/tests-gpu-py3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9013671875, 'info': {'test accuracy': 0.1006, 'train accuracy': 0.10498046875, 'validation accuracy': 0.0986328125, 'number of parameters': 39436}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from keras import backend as K\n",
    "except:\n",
    "    raise ImportError(\"For this example you need to install keras.\")\n",
    "\n",
    "try:\n",
    "    import torchvision\n",
    "    import torchvision.transforms as transforms\n",
    "except:\n",
    "    raise ImportError(\"For this example you need to install pytorch-vision.\")\n",
    "\n",
    "\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "class KerasWorker(Worker):\n",
    "    def __init__(self, N_train=8192, N_valid=1024, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "            self.batch_size = 64\n",
    "\n",
    "            img_rows = 28\n",
    "            img_cols = 28\n",
    "            self.num_classes = 10\n",
    "\n",
    "            # the data, split between train and test sets\n",
    "            (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "                    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "                    self.input_shape = (1, img_rows, img_cols)\n",
    "            else:\n",
    "                    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "                    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "                    self.input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "            x_train = x_train.astype('float32')\n",
    "            x_test = x_test.astype('float32')\n",
    "            # zero-one normalization\n",
    "            x_train /= 255\n",
    "            x_test /= 255\n",
    "\n",
    "\n",
    "            # convert class vectors to binary class matrices\n",
    "            y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "            y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "\n",
    "\n",
    "            self.x_train, self.y_train = x_train[:N_train], y_train[:N_train]\n",
    "            self.x_validation, self.y_validation = x_train[-N_valid:], y_train[-N_valid:]\n",
    "            self.x_test, self.y_test   = x_test, y_test\n",
    "\n",
    "            self.input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute(self, config, budget, working_directory, *args, **kwargs):\n",
    "            \"\"\"\n",
    "            Simple example for a compute function using a feed forward network.\n",
    "            It is trained on the MNIST dataset.\n",
    "            The input parameter \"config\" (dictionary) contains the sampled configurations passed by the bohb optimizer\n",
    "            \"\"\"\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(config['num_filters_1'], kernel_size=(3,3),\n",
    "                                             activation='relu',\n",
    "                                             input_shape=self.input_shape))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            if config['num_conv_layers'] > 1:\n",
    "                    model.add(Conv2D(config['num_filters_2'], kernel_size=(3, 3),\n",
    "                                                     activation='relu',\n",
    "                                                     input_shape=self.input_shape))\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            if config['num_conv_layers'] > 2:\n",
    "                    model.add(Conv2D(config['num_filters_3'], kernel_size=(3, 3),\n",
    "                                             activation='relu',\n",
    "                                             input_shape=self.input_shape))\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Dropout(config['dropout_rate']))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(config['num_fc_units'], activation='relu'))\n",
    "            model.add(Dropout(config['dropout_rate']))\n",
    "            model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "            if config['optimizer'] == 'Adam':\n",
    "                    optimizer = keras.optimizers.Adam(lr=config['lr'])\n",
    "            else:\n",
    "                    optimizer = keras.optimizers.SGD(lr=config['lr'], momentum=config['sgd_momentum'])\n",
    "\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                                      optimizer=optimizer,\n",
    "                                      metrics=['accuracy'])\n",
    "\n",
    "            model.fit(self.x_train, self.y_train,\n",
    "                              batch_size=self.batch_size,\n",
    "                              epochs=int(budget),\n",
    "                              verbose=0,\n",
    "                              validation_data=(self.x_test, self.y_test))\n",
    "\n",
    "            train_score = model.evaluate(self.x_train, self.y_train, verbose=0)\n",
    "            val_score = model.evaluate(self.x_validation, self.y_validation, verbose=0)\n",
    "            test_score = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "\n",
    "            #import IPython; IPython.embed()\n",
    "            return ({\n",
    "                    'loss': 1-val_score[1], # remember: HpBandSter always minimizes!\n",
    "                    'info': {       'test accuracy': test_score[1],\n",
    "                                            'train accuracy': train_score[1],\n",
    "                                            'validation accuracy': val_score[1],\n",
    "                                            'number of parameters': model.count_params(),\n",
    "                                    }\n",
    "\n",
    "            })\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "            \"\"\"\n",
    "            It builds the configuration space with the needed hyperparameters.\n",
    "            It is easily possible to implement different types of hyperparameters.\n",
    "            Beside float-hyperparameters on a log scale, it is also able to handle categorical input parameter.\n",
    "            :return: ConfigurationsSpace-Object\n",
    "            \"\"\"\n",
    "            cs = CS.ConfigurationSpace()\n",
    "\n",
    "            lr = CSH.UniformFloatHyperparameter('lr', lower=1e-6, upper=1e-1, default_value='1e-2', log=True)\n",
    "\n",
    "            # For demonstration purposes, we add different optimizers as categorical hyperparameters.\n",
    "            # To show how to use conditional hyperparameters with ConfigSpace, we'll add the optimizers 'Adam' and 'SGD'.\n",
    "            # SGD has a different parameter 'momentum'.\n",
    "            optimizer = CSH.CategoricalHyperparameter('optimizer', ['Adam', 'SGD'])\n",
    "\n",
    "            sgd_momentum = CSH.UniformFloatHyperparameter('sgd_momentum', lower=0.0, upper=0.99, default_value=0.9, log=False)\n",
    "\n",
    "            cs.add_hyperparameters([lr, optimizer, sgd_momentum])\n",
    "\n",
    "\n",
    "\n",
    "            num_conv_layers =  CSH.UniformIntegerHyperparameter('num_conv_layers', lower=1, upper=3, default_value=2)\n",
    "\n",
    "            num_filters_1 = CSH.UniformIntegerHyperparameter('num_filters_1', lower=4, upper=64, default_value=16, log=True)\n",
    "            num_filters_2 = CSH.UniformIntegerHyperparameter('num_filters_2', lower=4, upper=64, default_value=16, log=True)\n",
    "            num_filters_3 = CSH.UniformIntegerHyperparameter('num_filters_3', lower=4, upper=64, default_value=16, log=True)\n",
    "\n",
    "            cs.add_hyperparameters([num_conv_layers, num_filters_1, num_filters_2, num_filters_3])\n",
    "\n",
    "\n",
    "            dropout_rate = CSH.UniformFloatHyperparameter('dropout_rate', lower=0.0, upper=0.9, default_value=0.5, log=False)\n",
    "            num_fc_units = CSH.UniformIntegerHyperparameter('num_fc_units', lower=8, upper=256, default_value=32, log=True)\n",
    "\n",
    "            cs.add_hyperparameters([dropout_rate, num_fc_units])\n",
    "\n",
    "\n",
    "            # The hyperparameter sgd_momentum will be used,if the configuration\n",
    "            # contains 'SGD' as optimizer.\n",
    "            cond = CS.EqualsCondition(sgd_momentum, optimizer, 'SGD')\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            # You can also use inequality conditions:\n",
    "            cond = CS.GreaterThanCondition(num_filters_2, num_conv_layers, 1)\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            cond = CS.GreaterThanCondition(num_filters_3, num_conv_layers, 2)\n",
    "            cs.add_condition(cond)\n",
    "\n",
    "            return cs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    worker = KerasWorker(run_id='0')\n",
    "    cs = worker.get_configspace()\n",
    "\n",
    "    config = cs.sample_configuration().get_dictionary()\n",
    "    print(config)\n",
    "    res = worker.compute(config=config, budget=1, working_directory='.')\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
