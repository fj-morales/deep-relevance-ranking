{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# REMOVE!!\n",
    "from ir_utils import *\n",
    "\n",
    "# model\n",
    "\n",
    "from ir_lmart import *\n",
    "\n",
    "# HPO\n",
    "\n",
    "from hpo import *\n",
    "from HpoWorker import *\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "# from hpbandster.core.worker import Worker\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# HPO server and stuff\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import argparse\n",
    "\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "from hpbandster.optimizers import RandomSearch as RS\n",
    "from hpbandster.examples.commons import MyWorker\n",
    "import random\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tickets(max):\n",
    "    return {i:i for i in range(1,max)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "million_tickets = tickets(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(million_tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_budget_data_file(budget, query_list, train_data_file):\n",
    "    # Budget is percentage of training data: \n",
    "    # min_budget = 10%\n",
    "    # max_budget = 100%\n",
    "    if (int(budget) <= 100 or int(budget) >= 10):\n",
    "        len_queries = len(query_list)\n",
    "        budgeted_queries = round(len_queries * (budget / 100))\n",
    "        print('total budget:', len_queries)\n",
    "        print('allocated budget:', budgeted_queries)\n",
    "        train_budget_queries_file = train_data_file + '_budget' + str(budget)\n",
    "        if not os.path.exists(train_budget_queries_file):\n",
    "            with open(train_data_file, 'rt') as f_in:\n",
    "                with open(train_budget_queries_file, 'wt') as budget_file_out:\n",
    "                    for query_feature in f_in:                        \n",
    "                        qid = query_feature.split()[1].split(':')[1]\n",
    "#                         print(qid)\n",
    "                        if qid in query_list[0:budgeted_queries]:\n",
    "                            \n",
    "                            budget_file_out.write(query_feature)\n",
    "        else:\n",
    "            print(\"File already exists\")\n",
    "            return train_budget_queries_file                \n",
    "    else:\n",
    "        print('Budget is outside the limits (10% < b < 100%): ', budget)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def generate_run_file(pre_run_file, run_file):\n",
    "    \n",
    "    with open(pre_run_file, 'rt') as input_f:\n",
    "        pre_run = input_f.readlines()\n",
    "#         print(type(pre_run))\n",
    "    with open(run_file, 'wt') as out_f:\n",
    "        for line in pre_run:\n",
    "            out_f.write(line.replace('docid=','').replace('indri', 'lambdaMART'))\n",
    "        \n",
    "# In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fakeParser:\n",
    "    def __init__(self):\n",
    "        self.min_budget = 1\n",
    "        self.max_budget = 100\n",
    "        self.n_iterations = 20\n",
    "        self.n_workers = 1\n",
    "        self.hpo_method = 'rs'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Options and variables\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Example 1 - sequential and local execution.')\n",
    "    parser.add_argument('--min_budget',   type=int, help='Minimum (percentage) budget used during the optimization.',    default=10)\n",
    "    parser.add_argument('--max_budget',   type=int, help='Maximum (percentage) budget used during the optimization.',    default=100)\n",
    "    parser.add_argument('--n_iterations', type=int,   help='Number of iterations performed by the optimizer', default=500)\n",
    "    parser.add_argument('--n_workers', type=int,   help='Number of workers to run in parallel.', default=5)\n",
    "    parser.add_argument('--dataset',   type=str, help='')\n",
    "    parser.add_argument('--fold', type=str,   help='')\n",
    "    parser.add_argument('--hpo_method',   type=str, help='')\n",
    "\n",
    "#     args=parser.parse_args()\n",
    "    args = fakeParser()\n",
    "    \n",
    "    \n",
    "    hpo_method = args.hpo_method\n",
    "#     dataset = sys.argv[1] # 'bioasq'\n",
    "#     workdir = './' + dataset + '_dir/'\n",
    "#     data_split = sys.argv[2] # 'test'\n",
    "\n",
    "    dataset = 'bioasq'\n",
    "    workdir = './' + dataset + '_dir/'\n",
    "    data_split =  'train'\n",
    "    k_fold = 's1' \n",
    "    ranklib_location = '../../../ranklib/'\n",
    "    trec_eval_command = '../../eval/trec_eval'\n",
    "    \n",
    "    l2r_model = '_lmart_'\n",
    "    confdir = './' + dataset + '_config/'\n",
    "    enabled_features_file = confdir + dataset + l2r_model + 'enabled_features'\n",
    "    \n",
    "    metric2t = 'MAP' # 'MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)'\n",
    "    \n",
    "    ranker_type = '6' # LambdaMART\n",
    "    \n",
    "    # normalization: Feature Engineering?\n",
    "    norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "    \n",
    "    \n",
    "    if hpo_method == 'rs':\n",
    "        hpo_run_id = \"RandomSearch\"\n",
    "        # Start a nameserver (see example_3)\n",
    "        NS = hpns.NameServer(run_id = hpo_run_id, host='127.0.0.1', port=None)\n",
    "        NS.start()\n",
    "    elif hpo_method == 'bohb':\n",
    "        hpo_run_id = \"BOHB\"\n",
    "        NS = hpns.NameServer(run_id = hpo_run_id, host='127.0.0.1', port=None)\n",
    "        NS.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if (not args.fold or args.dataset == 'bioasq'):\n",
    "        args.fold = ['']\n",
    "    elif args.fold == 'all':\n",
    "        args.fold = ['1','2','3','4','5']\n",
    "    #         args.fold = ['1']\n",
    "    else:\n",
    "        args.fold = [args.fold]\n",
    "\n",
    "\n",
    "    for f in args.fold:\n",
    "\n",
    "        fold = f # '1'\n",
    "\n",
    "        if args.dataset == 'bioasq':\n",
    "            fold_dir = workdir\n",
    "            dataset_fold = dataset \n",
    "            train_queries_file = '../../bioasq_data/bioasq.' + 'train' + '.json'\n",
    "        else:\n",
    "            fold_dir = workdir + 's' + fold + '/'\n",
    "            dataset_fold = dataset + '_' + fold\n",
    "            train_queries_file = '../../robust04_data/split_' + fold + '/rob04.' +  'train' + '.s' + fold + '.json'\n",
    "            \n",
    "\n",
    "        train_data_file = fold_dir + dataset + '_train' + '_features'\n",
    "        val_data_file = fold_dir + dataset + '_dev' + '_features'\n",
    "        test_data_file = fold_dir + dataset + '_test' +  '_features'\n",
    "        qrels_val_file = fold_dir + dataset + '_dev' + '_qrels'\n",
    "        \n",
    "        l2r_params = [\n",
    "            '-validate',\n",
    "            val_data_file,\n",
    "            '-ranker',\n",
    "            ranker_type,\n",
    "            '-metric2t',\n",
    "            metric2t,\n",
    "            '-feature',\n",
    "            enabled_features_file\n",
    "        ]\n",
    "        \n",
    "        # Run train\n",
    "        lmart_model = L2Ranker(ranklib_location, l2r_params, norm_params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        save_model_prefix = fold_dir + dataset_fold + l2r_model\n",
    "        \n",
    "        run_file_prefix = fold_dir + 'run_' + dataset_fold + l2r_model\n",
    "\n",
    "        # Preparing budgeted train features data \n",
    "        query_list = load_queries(train_queries_file)\n",
    "        qid_list = [q['id'] for q in query_list] \n",
    "        len_queries = len(qid_list) \n",
    "        real_max_budget = round((len_queries * args.max_budget) / 100)\n",
    "        real_min_budget = round((len_queries * args.min_budget) / 100)\n",
    "\n",
    "        # train_features_file =  fold_dir + dataset + '_' + 'train' + '_features'\n",
    "        train_features_file =  fold_dir + dataset + '_' + 'train' + '_features'\n",
    "\n",
    "\n",
    "        budget_train_features_file = train_data_file\n",
    "        # budget_train_features_file = workdir + 'budget_ejemplo'\n",
    "\n",
    "        workers=[]\n",
    "        for i in range(args.n_workers):\n",
    "            worker = HpoWorker(lmart_model, save_model_prefix, run_file_prefix, budget_train_features_file, qid_list, trec_eval_command, \n",
    "                               qrels_val_file, million_tickets, nameserver='127.0.0.1',run_id=hpo_run_id, id=i)\n",
    "            worker.run(background=True)\n",
    "            workers.append(worker)\n",
    "\n",
    "\n",
    "        # In[13]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run an optimizer (see example_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search\n",
    "\n",
    "if hpo_method == 'rs':\n",
    "    rs = RS(  configspace = worker.get_configspace(),\n",
    "                          run_id = hpo_run_id, \n",
    "                          min_budget = real_max_budget, max_budget = real_max_budget\n",
    "                   )\n",
    "    res = rs.run(n_iterations = args.n_iterations, min_n_workers = args.n_workers)\n",
    "\n",
    "    rs.shutdown(shutdown_workers=True)\n",
    "elif hpo_method == 'bohb':\n",
    "    bohb = BOHB(  configspace = worker.get_configspace(),\n",
    "                          run_id = hpo_run_id, \n",
    "                          min_budget = real_min_budget, max_budget = real_max_budget\n",
    "                   )\n",
    "    res = bohb.run(n_iterations = args.n_iterations, min_n_workers = args.n_workers)\n",
    "    bohb.shutdown(shutdown_workers=True)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Step 4: Shutdown\n",
    "# After the optimizer run, we must shutdown the master and the nameserver.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NS.shutdown()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Step 5: Analysis\n",
    "# Each optimizer returns a hpbandster.core.result.Result object.\n",
    "# It holds informations about the optimization run like the incumbent (=best) configuration.\n",
    "# For further details about the Result object, see its documentation.\n",
    "# Here we simply print out the best config and some statistics about the performed runs.\n",
    "id2config = res.get_id2config_mapping()\n",
    "incumbent = res.get_incumbent_id()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "all_runs = res.get_all_runs()\n",
    "\n",
    "\n",
    "\n",
    "print('Best found configuration:', id2config[incumbent]['config'])\n",
    "print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "print('Total budget corresponds to %.1f full function evaluations.'%(sum([r.budget for r in all_runs])/args.max_budget))\n",
    "print('The run took  %.1f seconds to complete.'%(all_runs[-1].time_stamps['finished'] - all_runs[0].time_stamps['started']))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "#     qrels_test_file = './bioasq_dir/bioasq.test_qrels'\n",
    "#     run_val_file = './this.file'\n",
    "#     lmart_model = res['info']\n",
    "#     lmart_model.gen_run_file(test_data_file, run_val_file)\n",
    "#     eval(trec_eval_command, qrels_test_file, run_val_file)\n",
    "\n",
    "\n",
    "# In[10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.get_incumbent_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2config[res.get_incumbent_id()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.get_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.get_all_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.get_id2config_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
