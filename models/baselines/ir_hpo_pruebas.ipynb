{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# REMOVE!!\n",
    "from ir_utils import *\n",
    "\n",
    "# model\n",
    "\n",
    "from ir_lmart import *\n",
    "\n",
    "# HPO\n",
    "\n",
    "from hpo import *\n",
    "# from HpoWorker import *\n",
    "from HpoWorker_CV import *\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "# from hpbandster.core.worker import Worker\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# HPO server and stuff\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import argparse\n",
    "\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "from hpbandster.optimizers import RandomSearch as RS\n",
    "\n",
    "import random\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tickets(max):\n",
    "    return {i:i for i in range(1,max)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "million_tickets = tickets(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(million_tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_budget_data_file(budget, query_list, train_data_file):\n",
    "    # Budget is percentage of training data: \n",
    "    # min_budget = 10%\n",
    "    # max_budget = 100%\n",
    "    if (int(budget) <= 100 or int(budget) >= 10):\n",
    "        len_queries = len(query_list)\n",
    "        budgeted_queries = round(len_queries * (budget / 100))\n",
    "        print('total budget:', len_queries)\n",
    "        print('allocated budget:', budgeted_queries)\n",
    "        train_budget_queries_file = train_data_file + '_budget' + str(budget)\n",
    "        if not os.path.exists(train_budget_queries_file):\n",
    "            with open(train_data_file, 'rt') as f_in:\n",
    "                with open(train_budget_queries_file, 'wt') as budget_file_out:\n",
    "                    for query_feature in f_in:                        \n",
    "                        qid = query_feature.split()[1].split(':')[1]\n",
    "#                         print(qid)\n",
    "                        if qid in query_list[0:budgeted_queries]:\n",
    "                            \n",
    "                            budget_file_out.write(query_feature)\n",
    "        else:\n",
    "            print(\"File already exists\")\n",
    "            return train_budget_queries_file                \n",
    "    else:\n",
    "        print('Budget is outside the limits (10% < b < 100%): ', budget)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def generate_run_file(pre_run_file, run_file):\n",
    "    \n",
    "    with open(pre_run_file, 'rt') as input_f:\n",
    "        pre_run = input_f.readlines()\n",
    "#         print(type(pre_run))\n",
    "    with open(run_file, 'wt') as out_f:\n",
    "        for line in pre_run:\n",
    "            out_f.write(line.replace('docid=','').replace('indri', 'lambdaMART'))\n",
    "        \n",
    "# In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fakeParser:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'bioasq' \n",
    "        self.min_budget = 10\n",
    "        self.max_budget = 10\n",
    "        self.n_iterations = 1\n",
    "        self.n_workers = 1\n",
    "        self.hpo_method = 'rs'\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Options and variables\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Example 1 - sequential and local execution.')\n",
    "    parser.add_argument('--min_budget',   type=int, help='Minimum (percentage) budget used during the optimization.',    default=10)\n",
    "    parser.add_argument('--max_budget',   type=int, help='Maximum (percentage) budget used during the optimization.',    default=100)\n",
    "    parser.add_argument('--n_iterations', type=int,   help='Number of iterations performed by the optimizer', default=500)\n",
    "    parser.add_argument('--n_workers', type=int,   help='Number of workers to run in parallel.', default=5)\n",
    "    parser.add_argument('--dataset',   type=str, help='')\n",
    "#     parser.add_argument('--fold', type=str,   help='')\n",
    "    parser.add_argument('--hpo_method',   type=str, help='')\n",
    "\n",
    "#     args=parser.parse_args()\n",
    "    args = fakeParser()\n",
    "    \n",
    "    \n",
    "    hpo_method = args.hpo_method\n",
    "\n",
    "\n",
    "    dataset = args.dataset\n",
    "    workdir = './' + dataset + '_dir/'\n",
    "#     data_split =  'train'\n",
    "    ranklib_location = '../../../ranklib/'\n",
    "    trec_eval_command = '../../eval/trec_eval'\n",
    "    \n",
    "\n",
    "    \n",
    "    metric2t = 'MAP' # 'MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)'\n",
    "    \n",
    "    ranker_type = '6' # LambdaMART\n",
    "    \n",
    "    # normalization: Feature Engineering?\n",
    "    norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "    \n",
    "    \n",
    "    if hpo_method == 'rs':\n",
    "        hpo_run_id = \"RandomSearch\"\n",
    "        # Start a nameserver (see example_3)\n",
    "        NS = hpns.NameServer(run_id = hpo_run_id, host='127.0.0.1', port=None)\n",
    "        NS.start()\n",
    "    elif hpo_method == 'bohb':\n",
    "        hpo_run_id = \"BOHB\"\n",
    "        NS = hpns.NameServer(run_id = hpo_run_id, host='127.0.0.1', port=None)\n",
    "        NS.start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    workers=[]\n",
    "    for i in range(args.n_workers):\n",
    "        \n",
    "        \n",
    "        worker = HpoWorker(dataset, workdir, ranklib_location, norm_params, ranker_type,trec_eval_command, metric2t, million_tickets, nameserver='127.0.0.1',run_id=hpo_run_id, id=i)\n",
    "        worker.run(background=True)\n",
    "        workers.append(worker)\n",
    "\n",
    "\n",
    "        # In[13]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run an optimizer (see example_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total budget: 1751\n",
      "allocated budget: 175\n",
      "File already exists\n",
      "['java', '-jar', '../../../ranklib/RankLib-2.12.jar', '-train', './bioasq_dir/bioasq_train_features_budget175', '-norm', 'zscore', '-validate', './bioasq_dir/bioasq_dev_features', '-ranker', '6', '-metric2t', 'MAP', '-feature', './bioasq_config/bioasq_lmart_enabled_features', '-leaf', '60', '-shrinkage', '0.46', '-tree', '100', '-save', './bioasq_dir/bioasq_lmart_id1_budget10_leaves60_lr0.46_n100']\n",
      "Model saved:  ./bioasq_dir/bioasq_lmart_id1_budget10_leaves60_lr0.46_n100\n",
      "['../../eval/trec_eval', '-m', 'map', '-m', 'P.20', '-m', 'ndcg_cut.20', './bioasq_dir/bioasq_dev_qrels', './bioasq_dir/run_bioasq_lmart_id1_budget10_leaves60_lr0.46_n100']\n",
      "Run error:  None\n"
     ]
    }
   ],
   "source": [
    "# Random search\n",
    "\n",
    "if hpo_method == 'rs':\n",
    "    rs = RS(  configspace = worker.get_configspace(),\n",
    "                          run_id = hpo_run_id, \n",
    "                          min_budget = args.max_budget, max_budget = args.max_budget\n",
    "                   )\n",
    "    res = rs.run(n_iterations = args.n_iterations, min_n_workers = args.n_workers)\n",
    "\n",
    "    rs.shutdown(shutdown_workers=True)\n",
    "elif hpo_method == 'bohb':\n",
    "    bohb = BOHB(  configspace = worker.get_configspace(),\n",
    "                          run_id = hpo_run_id, \n",
    "                          min_budget = args.min_budget, max_budget = args.max_budget\n",
    "                   )\n",
    "    res = bohb.run(n_iterations = args.n_iterations, min_n_workers = args.n_workers)\n",
    "    bohb.shutdown(shutdown_workers=True)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Step 4: Shutdown\n",
    "# After the optimizer run, we must shutdown the master and the nameserver.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found configuration: {'learning_rate': 0.46, 'n_leaves': 60, 'n_trees': 100}\n",
      "A total of 1 unique configurations where sampled.\n",
      "A total of 1 runs where executed.\n",
      "Total budget corresponds to 1.0 full function evaluations.\n",
      "The run took  10.2 seconds to complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NS.shutdown()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Step 5: Analysis\n",
    "# Each optimizer returns a hpbandster.core.result.Result object.\n",
    "# It holds informations about the optimization run like the incumbent (=best) configuration.\n",
    "# For further details about the Result object, see its documentation.\n",
    "# Here we simply print out the best config and some statistics about the performed runs.\n",
    "id2config = res.get_id2config_mapping()\n",
    "incumbent = res.get_incumbent_id()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "all_runs = res.get_all_runs()\n",
    "\n",
    "\n",
    "\n",
    "print('Best found configuration:', id2config[incumbent]['config'])\n",
    "print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "print('Total budget corresponds to %.1f full function evaluations.'%(sum([r.budget for r in all_runs])/args.max_budget))\n",
    "print('The run took  %.1f seconds to complete.'%(all_runs[-1].time_stamps['finished'] - all_runs[0].time_stamps['started']))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "#     qrels_test_file = './bioasq_dir/bioasq.test_qrels'\n",
    "#     run_val_file = './this.file'\n",
    "#     lmart_model = res['info']\n",
    "#     lmart_model.gen_run_file(test_data_file, run_val_file)\n",
    "#     eval(trec_eval_command, qrels_test_file, run_val_file)\n",
    "\n",
    "\n",
    "# In[10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.get_incumbent_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'learning_rate': 0.46, 'n_leaves': 60, 'n_trees': 100},\n",
       " 'config_info': {}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2config[res.get_incumbent_id()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.get_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[config_id: (0, 0, 0)\tbudget: 10.000000\tloss: 0.3883\n",
       " time_stamps: 0.0013155937194824219 (submitted), 0.0014717578887939453 (started), 10.248464822769165 (finished)\n",
       " info: {'s': {'loss': 0.6117, 'info': {'map': '0.3883', 'P_20': '0.2270', 'ndcg_cut_20': '0.4883'}}, 'mean_loss': 0.6117, 'std_loss': 0.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.get_all_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): {'config': {'learning_rate': 0.46, 'n_leaves': 60, 'n_trees': 100},\n",
       "  'config_info': {}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.get_id2config_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
