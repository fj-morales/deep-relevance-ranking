{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "clean = lambda t: re.sub('[,?;*!%^&_+():-\\[\\]{}]', ' ', t.replace('\"', ' ').replace('/', ' ').replace('\\\\', ' ').replace(\"'\", ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('-', ' ').replace('.', '').replace('&hyph;', ' ').replace('&blank;', ' ').strip().lower())\n",
    "\n",
    "# To tokenize a text field, first preprocess it using the \"clean\" lambda function, then tokenize preproceesed text with nltk tokenizer.\n",
    "\n",
    "raw_text = 'This is&blank;some text\\t to preprocess!'\n",
    "preprocessed_text = clean(raw_text)\n",
    "tokens = nltk.word_tokenize(preprocessed_text)\n",
    "\n",
    "print('Raw text: {0}'.format(raw_text))\n",
    "print('Preprocessed text: {0}'.format(preprocessed_text))\n",
    "print('Tokens: {0}'.format(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(data_dir):\n",
    "    filenames = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(data_dir)\n",
    "             for name in files\n",
    "             if \"DS_Store\" not in name\n",
    "           ]\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/ssd/francisco/deep-relevance-ranking/robust04_data/collection/corpus/'\n",
    "output_dir = input_dir.rstrip('/')  + '2/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_filenames(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    file_out = output_dir + '/'.join(file.split('/')[-2:])\n",
    "#     print(file_out)\n",
    "    with open(file, 'rt', encoding = \"ISO-8859-1\") as i_f:\n",
    "        with open(file_out, 'wt') as o_f:\n",
    "            [o_f.write(clean(line)) for line in i_f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[-2:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
