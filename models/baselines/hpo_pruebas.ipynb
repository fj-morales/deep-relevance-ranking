{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# REMOVE!!\n",
    "from utils import *\n",
    "\n",
    "# model\n",
    "\n",
    "from ir_lmart import *\n",
    "\n",
    "# HPO\n",
    "\n",
    "from hpo import *\n",
    "from HpoWorker import *\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# HPO server and stuff\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import argparse\n",
    "\n",
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "from hpbandster.optimizers import RandomSearch as RS\n",
    "from hpbandster.examples.commons import MyWorker\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_budget_data_file(budget, query_list, train_data_file):\n",
    "    # Budget is percentage of training data: \n",
    "    # min_budget = 10%\n",
    "    # max_budget = 100%\n",
    "    if (int(budget) <= 100 or int(budget) >= 10):\n",
    "        len_queries = len(query_list)\n",
    "        budgeted_queries = round(len_queries * (budget / 100))\n",
    "        print('total budget:', len_queries)\n",
    "        print('allocated budget:', budgeted_queries)\n",
    "        train_budget_queries_file = train_data_file + '_budget' + str(budget)\n",
    "        if not os.path.exists(train_budget_queries_file):\n",
    "            with open(train_data_file, 'rt') as f_in:\n",
    "                with open(train_budget_queries_file, 'wt') as budget_file_out:\n",
    "                    for query_feature in f_in:                        \n",
    "                        qid = query_feature.split()[1].split(':')[1]\n",
    "#                         print(qid)\n",
    "                        if qid in query_list[0:budgeted_queries]:\n",
    "                            \n",
    "                            budget_file_out.write(query_feature)\n",
    "        else:\n",
    "            print(\"File already exists\")\n",
    "            return train_budget_queries_file                \n",
    "    else:\n",
    "        print('Budget is outside the limits (10% < b < 100%): ', budget)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def generate_run_file(pre_run_file, run_file):\n",
    "    \n",
    "    with open(pre_run_file, 'rt') as input_f:\n",
    "        pre_run = input_f.readlines()\n",
    "#         print(type(pre_run))\n",
    "    with open(run_file, 'wt') as out_f:\n",
    "        for line in pre_run:\n",
    "            out_f.write(line.replace('docid=','').replace('indri', 'lambdaMART'))\n",
    "        \n",
    "# In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fakeParser:\n",
    "    def __init__(self):\n",
    "        self.min_budget = 20 \n",
    "        self.max_budget = 20\n",
    "        self.n_iterations = 1\n",
    "        self.n_workers = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Options and variables\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Example 1 - sequential and local execution.')\n",
    "    parser.add_argument('--min_budget',   type=int, help='Minimum budget used during the optimization.',    default=10)\n",
    "    parser.add_argument('--max_budget',   type=int, help='Maximum budget used during the optimization.',    default=100)\n",
    "    parser.add_argument('--n_iterations', type=int,   help='Number of iterations performed by the optimizer', default=500)\n",
    "    parser.add_argument('--n_workers', type=int,   help='Number of workers to run in parallel.', default=5)\n",
    "\n",
    "#     args=parser.parse_args()\n",
    "    args = fakeParser()\n",
    "    \n",
    "#     dataset = sys.argv[1] # 'bioasq'\n",
    "#     workdir = './' + dataset + '_dir/'\n",
    "#     data_split = sys.argv[2] # 'test'\n",
    "\n",
    "    dataset = 'bioasq'\n",
    "    workdir = './' + dataset + '_dir/'\n",
    "    data_split =  'train'\n",
    "    k_fold = 's1' \n",
    "    ranklib_location = '../../../ranklib/'\n",
    "    \n",
    "#     train_data_file = './bioasq_dir/bioasq.trai_features_reduced'\n",
    "#     val_data_file = './bioasq_dir/bioasq.dev_features_reduced'\n",
    "#     test_data_file = './bioasq_dir/bioasq.test_features_reduced'\n",
    "    \n",
    "    train_data_file = './bioasq_dir/bioasq_train_features'\n",
    "    val_data_file = './bioasq_dir/bioasq_dev_features'\n",
    "    test_data_file = './bioasq_dir/bioasq_test_features'\n",
    "    \n",
    "    l2r_model = '_lmart_'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    confdir = './' + dataset + '_config/'\n",
    "    enabled_features_file = confdir + dataset + l2r_model + 'enabled_features'\n",
    "    \n",
    "#     print(enabled_features_file)\n",
    "    # Train L2R model: LambdaMART\n",
    "    # Parameters \n",
    "    \n",
    "#     n_leaves = '10'\n",
    "#     learning_rate = '0.1'\n",
    "#     n_trees = '1000'\n",
    "#     hpo_params = [n_leaves, learning_rate, n_trees]\n",
    "    \n",
    "    \n",
    "    \n",
    "    metric2t = 'MAP' # 'MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)'\n",
    "    \n",
    "    ranker_type = '6' # LambdaMART\n",
    "    \n",
    "    # normalization: Feature Engineering?\n",
    "    norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "    \n",
    "    l2r_params = [\n",
    "        '-validate',\n",
    "        val_data_file,\n",
    "        '-ranker',\n",
    "        ranker_type,\n",
    "        '-metric2t',\n",
    "        metric2t,\n",
    "        '-feature',\n",
    "        enabled_features_file\n",
    "    ]\n",
    "    \n",
    "    # Run train\n",
    "    \n",
    "#     lmart_model = L2Ranker(ranklib_location, l2r_params)\n",
    "    lmart_model = L2Ranker(ranklib_location, l2r_params, norm_params)\n",
    "    \n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#     lmart_model.train(train_data_file, hpo_params)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#     lmart_model.gen_run_file(test_data_file, run_file)\n",
    "\n",
    "\n",
    "# In[9]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_eval_command = '../../eval/trec_eval'\n",
    "qrels_val_file = './bioasq_dir/bioasq_dev_qrels'\n",
    "#     eval(trec_eval_command, qrels_file, './run_l2linear')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "#     # HPO \n",
    "\n",
    "    \n",
    "    \n",
    "# #     worker = HpoWorker(run_id='0')\n",
    "#     cs = worker.get_configspace()\n",
    "\n",
    "#     config = cs.sample_configuration().get_dictionary()\n",
    "    \n",
    "        \n",
    "# #     pre_run_file = workdir + 'pre_run_' + dataset + l2r_model\n",
    "    \n",
    "#     run_file = workdir + 'run_' + dataset + l2r_model\n",
    "    \n",
    "#     print(config)\n",
    "#     res = worker.compute(config=config)\n",
    "#     print(res['loss'])\n",
    "\n",
    "\n",
    "# In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total budget: 1751\n",
      "allocated budget: 350\n",
      "File already exists\n",
      "budget_file: ./bioasq_dir/bioasq_train_features_budget20\n",
      "Model saved:  ./bioasq_dir/ejemplo_model_leaves10_lr0.07_n110\n",
      "Aqui veo si genero o no el run file:  <class 'list'>\n",
      "['../../eval/trec_eval', '-m', 'map', '-m', 'P.20', '-m', 'ndcg_cut.20', './bioasq_dir/bioasq_dev_qrels', './bioasq_dir/run_ejemplo_leaves10_lr0.07_n110']\n",
      "Run error:  None\n",
      "Best found configuration: {'learning_rate': 0.07, 'n_leaves': 10, 'n_trees': 110}\n",
      "A total of 1 unique configurations where sampled.\n",
      "A total of 1 runs where executed.\n",
      "Total budget corresponds to 1.0 full function evaluations.\n",
      "Total budget corresponds to 1.0 full function evaluations.\n",
      "The run took  6.5 seconds to complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0): {'config': {'learning_rate': 0.07, 'n_leaves': 10, 'n_trees': 110},\n",
       "  'config_info': {'model_based_pick': False}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start a nameserver (see example_3)\n",
    "NS = hpns.NameServer(run_id='example1', host='127.0.0.1', port=None)\n",
    "NS.start()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "save_model_prefix = workdir + 'ejemplo_model'\n",
    "run_file_prefix = workdir + 'run_ejemplo'\n",
    "\n",
    "train_queries_file = '../../bioasq_data/bioasq.' + 'train' + '.json'\n",
    "            \n",
    "query_list = load_queries(train_queries_file)\n",
    "qid_list = [q['id'] for q in query_list] \n",
    "# train_features_file =  fold_dir + dataset + '_' + 'train' + '_features'\n",
    "train_features_file =  workdir + dataset + '_' + 'train' + '_features'\n",
    "\n",
    "\n",
    "budget_train_features_file = train_data_file\n",
    "# budget_train_features_file = workdir + 'budget_ejemplo'\n",
    "\n",
    "\n",
    "workers=[]\n",
    "for i in range(args.n_workers):\n",
    "    worker = HpoWorker(lmart_model, save_model_prefix, run_file_prefix, budget_train_features_file, qid_list, trec_eval_command, \n",
    "                       qrels_val_file, nameserver='127.0.0.1',run_id='example1', id=i)\n",
    "    worker.run(background=True)\n",
    "    workers.append(worker)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# Run an optimizer (see example_2)\n",
    "bohb = BOHB(  configspace = worker.get_configspace(),\n",
    "                      run_id = 'example1', \n",
    "                      min_budget = args.min_budget, max_budget = args.max_budget\n",
    "               )\n",
    "res = bohb.run(n_iterations = args.n_iterations, min_n_workers = args.n_workers)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Step 4: Shutdown\n",
    "# After the optimizer run, we must shutdown the master and the nameserver.\n",
    "bohb.shutdown(shutdown_workers=True)\n",
    "NS.shutdown()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Step 5: Analysis\n",
    "# Each optimizer returns a hpbandster.core.result.Result object.\n",
    "# It holds informations about the optimization run like the incumbent (=best) configuration.\n",
    "# For further details about the Result object, see its documentation.\n",
    "# Here we simply print out the best config and some statistics about the performed runs.\n",
    "id2config = res.get_id2config_mapping()\n",
    "incumbent = res.get_incumbent_id()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "all_runs = res.get_all_runs()\n",
    "\n",
    "\n",
    "\n",
    "print('Best found configuration:', id2config[incumbent]['config'])\n",
    "print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "print('Total budget corresponds to %.1f full function evaluations.'%(sum([r.budget for r in all_runs])/args.max_budget))\n",
    "print('Total budget corresponds to %.1f full function evaluations.'%(sum([r.budget for r in all_runs])/args.max_budget))\n",
    "print('The run took  %.1f seconds to complete.'%(all_runs[-1].time_stamps['finished'] - all_runs[0].time_stamps['started']))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "#     qrels_test_file = './bioasq_dir/bioasq.test_qrels'\n",
    "#     run_val_file = './this.file'\n",
    "#     lmart_model = res['info']\n",
    "#     lmart_model.gen_run_file(test_data_file, run_val_file)\n",
    "#     eval(trec_eval_command, qrels_test_file, run_val_file)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "id2config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
