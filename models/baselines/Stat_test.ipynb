{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import random\n",
    "import timeit\n",
    "from scipy import stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dev_algo_A = './bioasq_dir/run_bioasq_linearModel_test_filtered'\n",
    "# run_dev_algo_B = './bioasq_dir/run_bm25_bioasq_test_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qrels_file = './robust_dir/s1/robust_test_s1_qrels'\n",
    "# trec_eval_command = '../../eval/trec_eval'\n",
    "\n",
    "# run_dev_algo_A = './robust_dir/s1/run_robust_s1_best_lmart_test'\n",
    "\n",
    "# run_dev_algo_B = './robust_dir/s1/run_bm25_robust_test_s1'\n",
    "# # run_dev_algo_B = run_dev_algo_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp(x):\n",
    "    return 1 - abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanAP(list_X):\n",
    "    return np.mean([x for x in  list_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_A_B(paired_list):\n",
    "    map_A = meanAP([x[1] for x in paired_list])\n",
    "    map_B = meanAP([x[2] for x in paired_list])\n",
    "    return [map_A, map_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(int_list):\n",
    "    string = \"\"\n",
    "    int_list = [str(x) for x in int_list] \n",
    "    return string.join(int_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_avgs(trec_eval_command, metric, qrel, qret):\n",
    "    \n",
    "    params = ['-q', '-m']\n",
    "    toolkit_parameters = [\n",
    "                            trec_eval_command,\n",
    "                            *params,\n",
    "                            metric,\n",
    "                            qrel,\n",
    "                            qret]\n",
    "\n",
    "#     print(toolkit_parameters)\n",
    "\n",
    "    proc = subprocess.Popen(toolkit_parameters, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "    (out, err) = proc.communicate()\n",
    "##     print(out.decode(\"utf-8\"))\n",
    "#     print('Run error: ', err)\n",
    "    if err == None:\n",
    "        pass\n",
    "#         print('No errors')\n",
    "    out_split = out.decode(\"utf-8\").replace('\\tall\\t','').splitlines()[:-1]\n",
    "    out_dict = {item.split()[1]:float(item.split()[2]) for item in out_split}\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paired_list(dict_A, dict_B):\n",
    "    if not (set(dict_A.keys())  == set(dict_B.keys())):\n",
    "        print('Queries sets are different!')\n",
    "        return\n",
    "    paired_list = []\n",
    "    for k in dict_A.keys():\n",
    "        paired_list.append([k, dict_A[k], dict_B[k]])\n",
    "    return paired_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_paired_list(paired_list, b_filter):    \n",
    "    return [[p[0], p[b+1], p[comp(b)+1]] for p,b in zip(paired_list, b_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(permuted_maps, observed_value):\n",
    "    permuted_diff = [x[0] - x[1] for x in permuted_maps]\n",
    "    observed_value\n",
    "    count = 0\n",
    "    for i in permuted_diff:\n",
    "        if (i < -abs(observed_value)) or (i > abs(observed_value)):\n",
    "            count += 1\n",
    "#     print(count)\n",
    "    p_value = count / len(permuted_maps)\n",
    "    return [observed_value, p_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pvalue(paired_list, alpha= 0.05, max_iter=20000, min_i=1000):\n",
    "    '''Compute randomized two-tailed significance testing'''\n",
    "    \n",
    "    seen_filters = set()\n",
    "    permuted_maps = []\n",
    "    permuted_lists = []\n",
    "    for i in range(0, max_iter):\n",
    "        b_filter = list(np.random.randint(2, size=(len(paired_list),)))\n",
    "\n",
    "        while list_to_str(b_filter) in seen_filters:\n",
    "            b_filter = list(np.random.randint(2, size=(len(paired_list),)))\n",
    "    #         clear_output()\n",
    "            print('repeated')\n",
    "\n",
    "        perm_list = permute_paired_list(paired_list, b_filter)\n",
    "        permuted_lists.append(perm_list)\n",
    "\n",
    "        seen_filters.add(list_to_str(b_filter))\n",
    "        permuted_maps.append(map_A_B(perm_list))\n",
    "\n",
    "        maps_two_algorithms = map_A_B(paired_list)\n",
    "        map_diff_test = maps_two_algorithms[0] - maps_two_algorithms[1]\n",
    "        map_diff_test\n",
    "        \n",
    "        [obs_value, pvalue] = get_p_value(permuted_maps, map_diff_test)\n",
    "\n",
    "        if i > min_i:\n",
    "            if (pvalue < 0.01) or (pvalue > 0.1):\n",
    "                break\n",
    "        if i % 1000 == 0:\n",
    "            pass\n",
    "#             print(pvalue)\n",
    "            \n",
    "    # Compare against Student t-test 1sample\n",
    "    \n",
    "    np.random.seed(12345678)\n",
    "\n",
    "    rs_diff = [x[1] - x[2] for x in paired_list]\n",
    "\n",
    "    # rvs1 = [x[1] for x in paired_list]\n",
    "    # rvs2 = [x[2] for x in paired_list]\n",
    "    [t_statistic, t_pvalue] = stats.ttest_1samp(rs_diff,0)\n",
    "    \n",
    "    \n",
    "    if pvalue < alpha:\n",
    "        sign_flag = True\n",
    "    else:\n",
    "        sign_flag = False\n",
    "    \n",
    "    return {'Significant': str(sign_flag),\n",
    "            'rand_pvalue':pvalue,\n",
    "            't_pvalue': t_pvalue,\n",
    "            'Metric diff': obs_value,            \n",
    "            't_statistic': t_statistic\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset and hpo method\n",
    "\n",
    "\n",
    "bio_test_runs = ['./deep-relevance-ranking/models/baselines/bioasq_dir/bioasq_test_qrels', # qrel\n",
    "                 './deep-relevance-ranking/models/baselines/bioasq_dir/run_bm25_bioasq_test_filtered', # bm25\n",
    "                 './deep-relevance-ranking/models/baselines/bioasq_dir/run_bioasq_linearModel_test_filtered', # bm25+extra\n",
    "                 './deep-relevance-ranking/models/baselines/posit_results4/qret.txt', # Deep model\n",
    "                 './deep-relevance-ranking/models/baselines/bioasq_dir/run_bioasq_best_lmart_test_leaves15_lr0.07_n750' # lambdaMart                  \n",
    "                ]\n",
    "\n",
    "folds = ['s1', 's2', 's3', 's4', 's5']\n",
    "robust_test_runs = [['./deep-relevance-ranking/models/baselines/robust_dir/' + f + '/robust_test_' + f + '_qrels', # qrel\n",
    "                 './deep-relevance-ranking/models/baselines/robust_dir/' + f + '/run_bm25_robust_test_' + f, # bm25 \n",
    "                 './deep-relevance-ranking/models/baselines/robust_dir/' + f + '/run_robust_linearModel_test_' + f, # bm25+extra \n",
    "#                  '', # Deep model\n",
    "                 './deep-relevance-ranking/models/baselines/robust_dir/' + f + '/run_robust_' + f + '_best_lmart_test_leaves25_lr0.03_n450' # lambdaMart                  \n",
    "                ] for f in folds]\n",
    "\n",
    "\n",
    "tvqa_test_runs = ['./TVQA/workdir/gold_answer_qrels_test', # qrel\n",
    "                 './TVQA/workdir/retrieved_files/run_tfidf_test', # baseline \n",
    "                 './TVQA/deep_results/run_deep_test', # Deep model, check the results when it finishes the training\n",
    "                 './TVQA/workdir/retrieved_files/run_best_lmart_test_leaves5_lr0.44_n1350' # lambdaMart                  \n",
    "                ]\n",
    "\n",
    "file_dirs = [bio_test_runs, *robust_test_runs, tvqa_test_runs]\n",
    "# file_dirs = [bio_test_runs,  tvqa_test_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_eval_command = './trec_eval/trec_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A: run_bm25_bioasq_test_filtered : MAP :  0.4598\n",
      "Model B: run_bioasq_linearModel_test_filtered : MAP :  0.4641\n",
      "{'Significant': 'False', 'rand_pvalue': 0.5369261477045908, 't_pvalue': 0.5168462929992957, 'Metric diff': -0.004243249999999976, 't_statistic': -0.6487916502629775}\n",
      "Model A: run_bm25_bioasq_test_filtered : P.20 :  0.2558\n",
      "Model B: run_bioasq_linearModel_test_filtered : P.20 :  0.2609\n",
      "{'Significant': 'False', 'rand_pvalue': 0.15568862275449102, 't_pvalue': 0.1684344966907121, 'Metric diff': -0.005124999999999935, 't_statistic': -1.379755939450135}\n",
      "Model A: run_bm25_bioasq_test_filtered : NDCG_CUT.20 :  0.5518\n",
      "Model B: run_bioasq_linearModel_test_filtered : NDCG_CUT.20 :  0.5515\n",
      "{'Significant': 'False', 'rand_pvalue': 0.9730538922155688, 't_pvalue': 0.9699271457834753, 'Metric diff': 0.0002662499999999124, 't_statistic': 0.03772332398104928}\n",
      "Model A: run_bm25_bioasq_test_filtered : MAP :  0.4598\n",
      "Model B: qret.txt : MAP :  0.4763\n",
      "{'Significant': 'True', 'rand_pvalue': 0.001996007984031936, 't_pvalue': 0.0033938463770196046, 'Metric diff': -0.016519249999999985, 't_statistic': -2.9473005326272705}\n",
      "Model A: run_bm25_bioasq_test_filtered : P.20 :  0.2558\n",
      "Model B: qret.txt : P.20 :  0.2618\n",
      "{'Significant': 'False', 'rand_pvalue': 0.0551, 't_pvalue': 0.05729211819942408, 'Metric diff': -0.00599999999999995, 't_statistic': -1.9065873407387792}\n",
      "Model A: run_bm25_bioasq_test_filtered : NDCG_CUT.20 :  0.5518\n",
      "Model B: qret.txt : NDCG_CUT.20 :  0.5701\n",
      "{'Significant': 'True', 'rand_pvalue': 0.000998003992015968, 't_pvalue': 0.0018006552387456506, 'Metric diff': -0.018384000000000178, 't_statistic': -3.1424207679172165}\n",
      "Model A: run_bm25_bioasq_test_filtered : MAP :  0.4598\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : MAP :  0.4692\n",
      "{'Significant': 'False', 'rand_pvalue': 0.1536926147704591, 't_pvalue': 0.14501867696864665, 'Metric diff': -0.009346999999999939, 't_statistic': -1.460212231257566}\n",
      "Model A: run_bm25_bioasq_test_filtered : P.20 :  0.2558\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : P.20 :  0.2605\n",
      "{'Significant': 'False', 'rand_pvalue': 0.23253493013972057, 't_pvalue': 0.2096831790447498, 'Metric diff': -0.004749999999999921, 't_statistic': -1.2564632497888288}\n",
      "Model A: run_bm25_bioasq_test_filtered : NDCG_CUT.20 :  0.5518\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : NDCG_CUT.20 :  0.5576\n",
      "{'Significant': 'False', 'rand_pvalue': 0.39820359281437123, 't_pvalue': 0.38827842420099923, 'Metric diff': -0.005798750000000075, 't_statistic': -0.8636875779258486}\n",
      "Model A: run_bioasq_linearModel_test_filtered : MAP :  0.4641\n",
      "Model B: qret.txt : MAP :  0.4763\n",
      "{'Significant': 'False', 'rand_pvalue': 0.10778443113772455, 't_pvalue': 0.10615475451902721, 'Metric diff': -0.012276000000000009, 't_statistic': -1.6193840247824494}\n",
      "Model A: run_bioasq_linearModel_test_filtered : P.20 :  0.2609\n",
      "Model B: qret.txt : P.20 :  0.2618\n",
      "{'Significant': 'False', 'rand_pvalue': 0.8323353293413174, 't_pvalue': 0.842529484352192, 'Metric diff': -0.0008750000000000147, 't_statistic': -0.19878845003905063}\n",
      "Model A: run_bioasq_linearModel_test_filtered : NDCG_CUT.20 :  0.5515\n",
      "Model B: qret.txt : NDCG_CUT.20 :  0.5701\n",
      "{'Significant': 'True', 'rand_pvalue': 0.008982035928143712, 't_pvalue': 0.023589986113962638, 'Metric diff': -0.01865025000000009, 't_statistic': -2.272461090270715}\n",
      "Model A: run_bioasq_linearModel_test_filtered : MAP :  0.4641\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : MAP :  0.4692\n",
      "{'Significant': 'False', 'rand_pvalue': 0.4590818363273453, 't_pvalue': 0.4362241151780082, 'Metric diff': -0.0051037499999999625, 't_statistic': -0.7793694735909604}\n",
      "Model A: run_bioasq_linearModel_test_filtered : P.20 :  0.2609\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : P.20 :  0.2605\n",
      "{'Significant': 'False', 'rand_pvalue': 0.8782435129740519, 't_pvalue': 0.9049628547231203, 'Metric diff': 0.0003750000000000142, 't_statistic': 0.11947035437415135}\n",
      "Model A: run_bioasq_linearModel_test_filtered : NDCG_CUT.20 :  0.5515\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : NDCG_CUT.20 :  0.5576\n",
      "{'Significant': 'False', 'rand_pvalue': 0.34331337325349304, 't_pvalue': 0.34562494121259724, 'Metric diff': -0.006064999999999987, 't_statistic': -0.944227239936965}\n",
      "Model A: qret.txt : MAP :  0.4763\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : MAP :  0.4692\n",
      "{'Significant': 'False', 'rand_pvalue': 0.36726546906187624, 't_pvalue': 0.35548162488740587, 'Metric diff': 0.007172250000000047, 't_statistic': 0.9250834968395053}\n",
      "Model A: qret.txt : P.20 :  0.2618\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : P.20 :  0.2605\n",
      "{'Significant': 'False', 'rand_pvalue': 0.7704590818363274, 't_pvalue': 0.7754072471020124, 'Metric diff': 0.0012500000000000289, 't_statistic': 0.28550262114433567}\n",
      "Model A: qret.txt : NDCG_CUT.20 :  0.5701\n",
      "Model B: run_bioasq_best_lmart_test_leaves15_lr0.07_n750 : NDCG_CUT.20 :  0.5576\n",
      "{'Significant': 'False', 'rand_pvalue': 0.14171656686626746, 't_pvalue': 0.11980441790451805, 'Metric diff': 0.012585250000000103, 't_statistic': 1.558935579141198}\n",
      "Model A: run_bm25_robust_test_summed : MAP :  0.3543\n",
      "Model B: run_robust_linearModel_test_summed : MAP :  0.3766\n",
      "{'Significant': 'True', 'rand_pvalue': 0.00499001996007984, 't_pvalue': 0.0025489589047284593, 'Metric diff': -0.02235140562249005, 't_statistic': -3.048495718031237}\n",
      "Model A: run_bm25_robust_test_summed : P.20 :  0.3801\n",
      "Model B: run_robust_linearModel_test_summed : P.20 :  0.4008\n",
      "{'Significant': 'True', 'rand_pvalue': 0.008982035928143712, 't_pvalue': 0.00836096990211929, 'Metric diff': -0.020642168674698813, 't_statistic': -2.6584405566814038}\n",
      "Model A: run_bm25_robust_test_summed : NDCG_CUT.20 :  0.3929\n",
      "Model B: run_robust_linearModel_test_summed : NDCG_CUT.20 :  0.4067\n",
      "{'Significant': 'False', 'rand_pvalue': 0.11477045908183632, 't_pvalue': 0.10200224861282119, 'Metric diff': -0.013791566265060229, 't_statistic': -1.6413021147500466}\n",
      "Model A: run_bm25_robust_test_summed : MAP :  0.3543\n",
      "Model B: run_robust_summed_best_lmart_test_leaves25_lr0.03_n450 : MAP :  0.3833\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 5.124557893100645e-05, 'Metric diff': -0.029037751004016066, 't_statistic': -4.122032013533233}\n",
      "Model A: run_bm25_robust_test_summed : P.20 :  0.3801\n",
      "Model B: run_robust_summed_best_lmart_test_leaves25_lr0.03_n450 : P.20 :  0.41\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 7.034427351511937e-05, 'Metric diff': -0.029879116465863442, 't_statistic': -4.043469421141001}\n",
      "Model A: run_bm25_robust_test_summed : NDCG_CUT.20 :  0.3929\n",
      "Model B: run_robust_summed_best_lmart_test_leaves25_lr0.03_n450 : NDCG_CUT.20 :  0.4219\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 0.00012472372957445486, 'Metric diff': -0.029033734939759026, 't_statistic': -3.8983168411820732}\n",
      "Model A: run_robust_linearModel_test_summed : MAP :  0.3489\n",
      "Model B: run_robust_summed_best_lmart_test_leaves25_lr0.03_n450 : MAP :  0.3833\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 2.1377758447174663e-06, 'Metric diff': -0.03435662650602406, 't_statistic': -4.854426423625976}\n",
      "Model A: run_robust_linearModel_test_summed : P.20 :  0.3731\n",
      "Model B: run_robust_summed_best_lmart_test_leaves25_lr0.03_n450 : P.20 :  0.41\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 5.990379377274707e-07, 'Metric diff': -0.036907228915662615, 't_statistic': -5.124941485979084}\n",
      "Model A: run_robust_linearModel_test_summed : NDCG_CUT.20 :  0.379\n",
      "Model B: run_robust_summed_best_lmart_test_leaves25_lr0.03_n450 : NDCG_CUT.20 :  0.4219\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 8.665772972653627e-08, 'Metric diff': -0.04291244979919684, 't_statistic': -5.516900281228739}\n",
      "Model A: run_tfidf_test : SUCCESS.1 :  0.5242\n",
      "Model B: run_deep_test : SUCCESS.1 :  0.6586\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 2.0771385903898689e-218, 'Metric diff': -0.13439979020520554, 't_statistic': -32.06748590367127}\n",
      "Model A: run_tfidf_test : SUCCESS.1 :  0.5242\n",
      "Model B: run_best_lmart_test_leavesummed_lr0.44_n1350 : SUCCESS.1 :  0.563\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 1.9414127671468704e-36, 'Metric diff': -0.0387464761030617, 't_statistic': -12.639740251532006}\n",
      "Model A: run_deep_test : SUCCESS.1 :  0.6586\n",
      "Model B: run_best_lmart_test_leavesummed_lr0.44_n1350 : SUCCESS.1 :  0.563\n",
      "{'Significant': 'True', 'rand_pvalue': 0.0, 't_pvalue': 2.9691346019264735e-124, 'Metric diff': 0.09565331410214384, 't_statistic': 23.92869230541027}\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20000\n",
    "\n",
    "min_i =1000\n",
    "alpha = 0.05\n",
    "\n",
    "# initial_b_filter = [1] * 400\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "dict_A = {}\n",
    "dict_B = {}\n",
    "metrics_deep = ['map', 'P.20', 'ndcg_cut.20']\n",
    "\n",
    "for fdir in file_dirs:\n",
    "    \n",
    "    qrels_file = fdir[0]    \n",
    "    if 'TVQA' in qrels_file:\n",
    "        metrics = ['success.1']\n",
    "    else:\n",
    "        metrics = metrics_deep\n",
    "    comb_folder = list(itertools.combinations(fdir[1:],2))\n",
    "\n",
    "\n",
    "    if ('robust' in qrels_file) and (any(x in qrels_file for x in ['s2', 's3', 's4', 's5'])):        \n",
    "        pass\n",
    "    else:\n",
    "        dict_A = {}\n",
    "        dict_B = {}\n",
    "\n",
    "    for comb in comb_folder:\n",
    "        for metric in metrics:\n",
    "            model_A = comb[0]\n",
    "            model_B = comb[1]\n",
    "\n",
    "\n",
    "            dict_part_A = get_run_avgs(trec_eval_command, metric, qrels_file, model_A)\n",
    "            dict_part_B = get_run_avgs(trec_eval_command, metric, qrels_file, model_B)\n",
    "\n",
    "            if ('robust' in qrels_file) and not ('s5' in qrels_file):\n",
    "                dict_A.update(dict_part_A)\n",
    "                dict_B.update(dict_part_B)\n",
    "\n",
    "                continue\n",
    "            elif ('robust' in qrels_file) and  ('s5' in qrels_file):\n",
    "                dict_A.update(dict_part_A)\n",
    "                dict_B.update(dict_part_B)\n",
    "#                 print(\"HEHE: \", len(dict_A), len(dict_B))\n",
    "\n",
    "\n",
    "            dict_A.update(dict_part_A)\n",
    "            dict_B.update(dict_part_B)\n",
    "\n",
    "    #         print(\"HEHE2: \", len(dict_A))\n",
    "    #         print(\"HEHE2: \", len(dict_B))\n",
    "\n",
    "            paired_list = get_paired_list(dict_A, dict_B)\n",
    "\n",
    "            metric_A = meanAP(list(dict_A.values()))\n",
    "            metric_B = meanAP(list(dict_B.values()))\n",
    "\n",
    "            results = compute_pvalue(paired_list, alpha, max_iter, min_i=1000)\n",
    "\n",
    "            print('Model A: ' + model_A.split('/')[-2:][-1].replace('s5', 'summed'), ':', metric.upper(), ': ' , round(metric_A,4))\n",
    "\n",
    "            print('Model B: ' + model_B.split('/')[-2:][-1].replace('s5', 'summed'), ':', metric.upper(), ': ', round(metric_B,4))\n",
    "            print(results)\n",
    "    #         print('Time spent: ', timeit.default_timer() - start_time, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
