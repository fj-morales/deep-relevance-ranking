{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reanking BM25 + extra features with linear model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "# For Linear model\n",
    "# Inspiration from:\n",
    "# https://opensourceconnections.com/blog/2017/04/01/learning-to-rank-linear-models/\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from math import sin\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "# REMOVE!!\n",
    "from ir_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(features_file):\n",
    "    with open(features_file, 'rt') as ff:\n",
    "        rels = []\n",
    "        qids = []\n",
    "        features =  []\n",
    "        docids = []\n",
    "        for feature_line in ff:\n",
    "            cols = feature_line.split(' ')\n",
    "            rels.append(cols[0])\n",
    "            qids.append(cols[1].split(':')[1])\n",
    "            features.append([x.split(':')[1] for x in cols[2:-1]])\n",
    "            docids.append(cols[-1:][0].split('=')[1].strip('\\n'))\n",
    "    return [np.array(rels, dtype=np.int), \n",
    "            qids, \n",
    "            np.array(features, dtype=np.float), \n",
    "            docids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(train_features_file):\n",
    "    [rels, qids, features, docids] = load_features(train_features_file)\n",
    "    \n",
    "    # Slice info for L2R Linear Model (Deep Relevance Ranking paper)\n",
    "    # 4 extra features\n",
    "    extra_features = features[:,-4:]\n",
    "    \n",
    "    \n",
    "    # Fitting linear model\n",
    "    # Ordinary Least Squares Linear Regression \n",
    "    linearModel = LinearRegression()\n",
    "    linearModel.fit(extra_features, rels)\n",
    "    \n",
    "#     print(linearModel.coef_)\n",
    "#     print(linearModel.intercept_)\n",
    "    return linearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_file, linear_model):\n",
    "    [rels, qids, features, docids] = load_features(test_file)\n",
    "    extra_features = features[:,-4:]\n",
    "#     extra_features = features\n",
    "    \n",
    "    predictions = linear_model.predict(extra_features)\n",
    "    print(len(predictions))\n",
    "    \n",
    "    queries_dict = {}\n",
    "    for i, qid in enumerate(qids):\n",
    "        if qid not in queries_dict.keys():\n",
    "            queries_dict[qid] = [[qid, docids[i], predictions[i]]]\n",
    "        else:\n",
    "#             print(qid, docids[i], predictions[i])\n",
    "            queries_dict[qid].append([qid, docids[i], predictions[i]])\n",
    "    \n",
    "    # Sort predictions\n",
    "    {qid:value.sort(key=lambda x: x[2], reverse=True) for (qid, value) in queries_dict.items()}\n",
    "    # Add ranking number\n",
    "    {qid:[x.append(value.index(x) + 1) for x in value] for (qid, value) in queries_dict.items()}\n",
    "\n",
    "    return queries_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_run_file(predictions_dict, filename):\n",
    "    with open(filename, 'wt') as f_out:\n",
    "        for qid, value in predictions_dict.items():\n",
    "            [f_out.write(x[0] + ' Q0 ' +  x[1] + ' ' + str(x[3]) + ' ' + str(x[2])[0:7] + ' linearModel\\n') for x in value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "## System inputs, main variable options\n",
    "\n",
    "#     dataset = sys.argv[1] # 'bioasq'\n",
    "#     workdir = './' + dataset + '_dir/'\n",
    "#     data_split = sys.argv[2] # 'test'\n",
    "\n",
    "#     features_file = './bioasq_dir/bioasq.dev_features'\n",
    "    workdir = './robust_dir/'\n",
    "    fold = 's1'\n",
    "    fold_dir = workdir + fold + '/'\n",
    "    \n",
    "    if not os.path.exists(fold_dir):\n",
    "        os.makedirs(fold_dir)\n",
    "    \n",
    "    train_features_file = fold_dir+ 'rob04.train.' + fold + '_features'\n",
    "    test_features_file = fold_dir + 'rob04.test.' + fold + '_features'\n",
    "    \n",
    "    # train model\n",
    "    linear_model = train_linear_model(train_features_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47807\n"
     ]
    }
   ],
   "source": [
    "    # predict\n",
    "    ranked_dict = predict(test_features_file, linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    run_linear_model_file = fold_dir + 'run_rob04_linearModel.test.' + fold\n",
    "    write_predictions_run_file(ranked_dict, run_linear_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'map                   \\tall\\t0.2442\\nP_20                  \\tall\\t0.3530\\nndcg_cut_20           \\tall\\t0.3950\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    trec_eval_command = '../../eval/trec_eval'\n",
    "    qrels_file = fold_dir + 'rob04.test.' + fold + '_qrels'\n",
    "    eval(trec_eval_command, qrels_file, run_linear_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'map                   \\tall\\t0.2416\\nP_20                  \\tall\\t0.3470\\nndcg_cut_20           \\tall\\t0.4188\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    qrels_file = fold_dir + 'rob04.test.' + fold + '_qrels'\n",
    "    run_bm25_file = fold_dir + 'run_bm25_rob04.test.' + fold \n",
    "    eval(trec_eval_command, qrels_file, run_bm25_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'map                   \\tall\\t0.1509\\nP_20                  \\tall\\t0.2180\\nndcg_cut_20           \\tall\\t0.3062\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    qrels_file = fold_dir + 'rob04.test.' + fold + '_qrels'\n",
    "    run_lmart_file = './robust_dir/s1/run_rob04.s1_lmart'\n",
    "    eval(trec_eval_command, qrels_file, run_lmart_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02229980127618244"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
