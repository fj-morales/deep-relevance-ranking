{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger baseline: Listwise L2R - LambdaMART\n",
    "# Hyperparameter optimziation HPonsteroids requires Python 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# REMOVE!!\n",
    "from ir_baseline import *\n",
    "\n",
    "# HPO\n",
    "\n",
    "\n",
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "\n",
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def generate_run_file(pre_run_file, run_file):\n",
    "    \n",
    "    with open(pre_run_file, 'rt') as input_f:\n",
    "        pre_run = input_f.readlines()\n",
    "        print(type(pre_run))\n",
    "    with open(run_file, 'wt') as out_f:\n",
    "        for line in pre_run:\n",
    "            out_f.write(line.replace('docid=','').replace('indri', 'lambdaMART'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "class L2Ranker:\n",
    "    def __init__(self, ranklib_location, params, normalization=[]):\n",
    "        self.ranklib_location = ranklib_location\n",
    "        # Works with Oracle JSE\n",
    "        # java version \"1.8.0_211\"\n",
    "        # Java(TM) SE Runtime Environment (build 1.8.0_211-b12)\n",
    "        # Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)\n",
    "        self.params = params\n",
    "        self.log_file = self.params[-1:][0] + '.log'\n",
    "        self.ranker_command = ['java', '-jar', ranklib_location + 'RankLib-2.12.jar']\n",
    "        self.normalization = normalization\n",
    "        self.save_model_file = ''\n",
    "        \n",
    "#     def build(self, ir_tool_params):\n",
    "    def train(self, train_data_file, save_model_file, hpo_config):\n",
    "        self.save_model_file = save_model_file\n",
    "        toolkit_parameters = [\n",
    "                                *self.ranker_command, # * to unpack list elements\n",
    "                                '-train',\n",
    "                                train_data_file,\n",
    "                                *self.normalization,\n",
    "                                *self.params,\n",
    "                                '-leaf', \n",
    "                                str(hpo_config['n_leaves']),\n",
    "                                '-shrinkage',\n",
    "                                str(hpo_config['learning_rate']),\n",
    "                                '-tree', # Fix: is this necessary according to original paper?\n",
    "                                str(hpo_config['n_trees']),\n",
    "                                '-save',\n",
    "                                self.save_model_file   \n",
    "                            ] \n",
    "        \n",
    "        print(toolkit_parameters)\n",
    "        with open(self.log_file, 'wt') as rf:\n",
    "            proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=rf, stderr=subprocess.STDOUT, shell=False)\n",
    "#         proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "            \n",
    "        (out, err)= proc.communicate()\n",
    "#         print(out.decode('utf-8').splitlines())\n",
    "#         print(out)\n",
    "#         print(err)\n",
    "        print('Model saved: ', self.save_model_file)\n",
    "            \n",
    "  \n",
    "\n",
    "    def gen_run_file(self, test_data_file, run_file):\n",
    "        pre_run_file = run_file.replace('run_', 'pre_run_', 1)\n",
    "        toolkit_parameters = [\n",
    "                                *self.ranker_command, # * to unpack list elements\n",
    "                                '-load',\n",
    "                                self.save_model_file,\n",
    "                                *self.normalization,\n",
    "                                '-rank',\n",
    "                                test_data_file,\n",
    "                                '-indri',\n",
    "                                pre_run_file     \n",
    "                            ] \n",
    "        \n",
    "        print(toolkit_parameters)\n",
    "        with open(self.log_file, 'at') as rf:\n",
    "            proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=rf, stderr=subprocess.STDOUT, shell=False)\n",
    "#         proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "            \n",
    "        (out, err)= proc.communicate()\n",
    "#         print(out.decode('utf-8').splitlines())\n",
    "#         print(out)\n",
    "#         print(err)\n",
    "\n",
    "        \n",
    "        generate_run_file(pre_run_file, run_file)\n",
    "        \n",
    "        print('Run model saved: ', run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     import keras\n",
    "#     from keras.datasets import mnist\n",
    "#     from keras.models import Sequential\n",
    "#     from keras.layers import Dense, Dropout, Flatten\n",
    "#     from keras.layers import Conv2D, MaxPooling2D\n",
    "#     from keras import backend as K\n",
    "# except:\n",
    "#     raise ImportError(\"For this example you need to install keras.\")\n",
    "\n",
    "# try:\n",
    "#     import torchvision\n",
    "#     import torchvision.transforms as transforms\n",
    "# except:\n",
    "#     raise ImportError(\"For this example you need to install pytorch-vision.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HpoWorker(Worker):\n",
    "    def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.run_val_file = ''\n",
    "            self.save_model_file = ''\n",
    "\n",
    "            \n",
    "    def compute(self, hpo_config, working_directory, *args, **kwargs):\n",
    "            \"\"\"\n",
    "            Simple example for a compute function using a feed forward network.\n",
    "            It is trained on the MNIST dataset.\n",
    "            The input parameter \"config\" (dictionary) contains the sampled configurations passed by the bohb optimizer\n",
    "            \"\"\"\n",
    "            \n",
    "            # Train model with config parameters\n",
    "            \n",
    "            \n",
    "                \n",
    "            #     pre_run_file = workdir + 'pre_run_' + dataset + l2r_model\n",
    "            \n",
    "            n_l = hpo_config['n_leaves']\n",
    "            l_r = hpo_config['learning_rate']\n",
    "            n_t = hpo_config['n_trees']\n",
    "            \n",
    "            config_suffix = '_leaves' + str(n_l) + '_lr' + str(l_r) + '_n' + str(n_t)\n",
    "            self.run_val_file = workdir + 'run_' + dataset + l2r_model + config_suffix\n",
    "            self.save_model_file = workdir + dataset + l2r_model + config_suffix\n",
    "            \n",
    "#             lmart_model = L2Ranker(ranklib_location, l2r_params)\n",
    "            lmart_model = L2Ranker(ranklib_location, l2r_params, norm_params)\n",
    "            lmart_model.train(train_data_file, self.save_model_file, hpo_config)\n",
    "            lmart_model.gen_run_file(val_data_file, self.run_val_file)\n",
    "            \n",
    "            # Evaluate Model\n",
    "            \n",
    "            val_results = eval(trec_eval_command, qrels_val_file, self.run_val_file)\n",
    "            val_results = val_results.splitlines()\n",
    "            val_map = float(val_results[0].split()[-1:][0])\n",
    "            print(val_map)\n",
    "\n",
    "            #import IPython; IPython.embed()\n",
    "            return ({\n",
    "                    'loss': 1 - val_map, # remember: HpBandSter always minimizes!\n",
    "                    'model': lmart_model\n",
    "            })\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "            \"\"\"\n",
    "            It builds the configuration space with the needed hyperparameters.\n",
    "            It is easily possible to implement different types of hyperparameters.\n",
    "            Beside float-hyperparameters on a log scale, it is also able to handle categorical input parameter.\n",
    "            :return: ConfigurationsSpace-Object\n",
    "            \"\"\"\n",
    "            cs = CS.ConfigurationSpace()\n",
    "            \n",
    "            n_leaves = CSH.UniformIntegerHyperparameter('n_leaves', lower=1, upper=20, default_value=10, q=10, log=False)\n",
    "            learning_rate = CSH.UniformFloatHyperparameter('learning_rate', lower=0.1, upper=0.9, default_value=0.1, q=10, log=False)\n",
    "            n_trees = CSH.UniformIntegerHyperparameter('n_trees', lower=1, upper=1000, default_value=1000, q=10, log=False)\n",
    "            \n",
    "            cs.add_hyperparameters([n_leaves, learning_rate, n_trees])\n",
    "\n",
    "            return cs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bioasq_dir/bioasq_lmart_enabled_features\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Options and variables\n",
    "#     dataset = sys.argv[1] # 'bioasq'\n",
    "#     workdir = './' + dataset + '_dir/'\n",
    "#     data_split = sys.argv[2] # 'test'\n",
    "\n",
    "    dataset = 'bioasq'\n",
    "    workdir = './' + dataset + '_dir/'\n",
    "    data_split =  'train'\n",
    "    k_fold = 's1' \n",
    "    ranklib_location = '../../../ranklib/'\n",
    "    \n",
    "#     train_data_file = './bioasq_dir/bioasq.trai_features_reduced'\n",
    "#     val_data_file = './bioasq_dir/bioasq.dev_features_reduced'\n",
    "#     test_data_file = './bioasq_dir/bioasq.test_features_reduced'\n",
    "    \n",
    "    train_data_file = './bioasq_dir/bioasq.trai_features'\n",
    "    val_data_file = './bioasq_dir/bioasq.dev_features'\n",
    "    test_data_file = './bioasq_dir/bioasq.test_features'\n",
    "    \n",
    "    l2r_model = '_lmart_'\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    enabled_features_file = workdir + dataset + l2r_model + 'enabled_features'\n",
    "    \n",
    "    print(enabled_features_file)\n",
    "    # Train L2R model: LambdaMART\n",
    "    # Parameters \n",
    "    \n",
    "#     n_leaves = '10'\n",
    "#     learning_rate = '0.1'\n",
    "#     n_trees = '1000'\n",
    "#     hpo_params = [n_leaves, learning_rate, n_trees]\n",
    "    \n",
    "    \n",
    "    \n",
    "    metric2t = 'MAP' # 'MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)'\n",
    "    \n",
    "    ranker_type = '6' # LambdaMART\n",
    "    \n",
    "    # normalization: Feature Engineering?\n",
    "    norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "    \n",
    "    l2r_params = [\n",
    "        '-validate',\n",
    "        val_data_file,\n",
    "        '-ranker',\n",
    "        ranker_type,\n",
    "        '-metric2t',\n",
    "        metric2t,\n",
    "        '-feature',\n",
    "        enabled_features_file\n",
    "    ]\n",
    "    \n",
    "    # Run train\n",
    "    \n",
    "#     lmart_model = L2Ranker(ranklib_location, l2r_params)\n",
    "#     lmart_model = L2Ranker(ranklib_location, l2r_params, norm_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     lmart_model.train(train_data_file, hpo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     lmart_model.gen_run_file(test_data_file, run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    trec_eval_command = '../../eval/trec_eval'\n",
    "    qrels_val_file = './bioasq_dir/bioasq.dev_qrels'\n",
    "#     eval(trec_eval_command, qrels_file, './run_l2linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_leaves': 10, 'n_trees': 380}\n",
      "['java', '-jar', '../../../ranklib/RankLib-2.12.jar', '-train', './bioasq_dir/bioasq.trai_features', '-norm', 'zscore', '-validate', './bioasq_dir/bioasq.dev_features', '-ranker', '6', '-metric2t', 'MAP', '-feature', './bioasq_dir/bioasq_lmart_enabled_features', '-leaf', '10', '-shrinkage', '0.1', '-tree', '380', '-save', './bioasq_dir/bioasq_lmart__leaves10_lr0.1_n380']\n",
      "Model saved:  ./bioasq_dir/bioasq_lmart__leaves10_lr0.1_n380\n",
      "['java', '-jar', '../../../ranklib/RankLib-2.12.jar', '-load', './bioasq_dir/bioasq_lmart__leaves10_lr0.1_n380', '-norm', 'zscore', '-rank', './bioasq_dir/bioasq.dev_features', '-indri', './bioasq_dir/pre_run_bioasq_lmart__leaves10_lr0.1_n380']\n",
      "<class 'list'>\n",
      "Run model saved:  ./bioasq_dir/run_bioasq_lmart__leaves10_lr0.1_n380\n",
      "['../../eval/trec_eval', '-m', 'map', '-m', 'P.20', '-m', 'ndcg_cut.20', './bioasq_dir/bioasq.dev_qrels', './bioasq_dir/run_bioasq_lmart__leaves10_lr0.1_n380']\n",
      "map                   \tall\t0.4409\n",
      "P_20                  \tall\t0.2635\n",
      "ndcg_cut_20           \tall\t0.5424\n",
      "\n",
      "Run error:  None\n",
      "No errors\n",
      "0.4409\n",
      "0.5590999999999999\n"
     ]
    }
   ],
   "source": [
    "    # HPO \n",
    "    working_directory = './hpo_workdir/'\n",
    "    \n",
    "    \n",
    "    worker = HpoWorker(run_id='0')\n",
    "    cs = worker.get_configspace()\n",
    "\n",
    "    config = cs.sample_configuration().get_dictionary()\n",
    "    \n",
    "        \n",
    "#     pre_run_file = workdir + 'pre_run_' + dataset + l2r_model\n",
    "    \n",
    "    run_file = workdir + 'run_' + dataset + l2r_model\n",
    "    \n",
    "    print(config)\n",
    "    res = worker.compute(hpo_config=config, working_directory='.')\n",
    "    print(res['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['java', '-jar', '../../../ranklib/RankLib-2.12.jar', '-load', './bioasq_dir/bioasq_lmart__leaves10_lr0.1_n380', '-norm', 'zscore', '-rank', './bioasq_dir/bioasq.test_features', '-indri', './this.file']\n",
      "<class 'list'>\n",
      "Run model saved:  ./this.file\n",
      "['../../eval/trec_eval', '-m', 'map', '-m', 'P.20', '-m', 'ndcg_cut.20', './bioasq_dir/bioasq.test_qrels', './this.file']\n",
      "map                   \tall\t0.4721\n",
      "P_20                  \tall\t0.2687\n",
      "ndcg_cut_20           \tall\t0.5649\n",
      "\n",
      "Run error:  None\n",
      "No errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'map                   \\tall\\t0.4721\\nP_20                  \\tall\\t0.2687\\nndcg_cut_20           \\tall\\t0.5649\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    qrels_test_file = './bioasq_dir/bioasq.test_qrels'\n",
    "    run_val_file = './this.file'\n",
    "    lmart_model = res['model']\n",
    "    lmart_model.gen_run_file(test_data_file, run_val_file)\n",
    "    eval(trec_eval_command, qrels_test_file, run_val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
