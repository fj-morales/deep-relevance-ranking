{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stronger baseline: Listwise L2R - LambdaMART\n",
    "# Hyperparameter optimziation HPonsteroids requires Python 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# REMOVE!!\n",
    "from ir_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def generate_run_file(pre_run_file, run_file):\n",
    "    \n",
    "    with open(pre_run_file, 'rt') as input_f:\n",
    "        pre_run = input_f.readlines()\n",
    "        print(type(pre_run))\n",
    "    with open(run_file, 'wt') as out_f:\n",
    "        for line in pre_run:\n",
    "            out_f.write(line.replace('docid=','').replace('indri', 'lambdaMART'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "class L2Ranker:\n",
    "    def __init__(self, ranklib_location, params, normalization=[]):\n",
    "        self.ranklib_location = ranklib_location\n",
    "        # Works with Oracle JSE\n",
    "        # java version \"1.8.0_211\"\n",
    "        # Java(TM) SE Runtime Environment (build 1.8.0_211-b12)\n",
    "        # Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)\n",
    "        self.params = params\n",
    "        self.log_file = self.params[-1:][0] + '.log'\n",
    "        self.ranker_command = ['java', '-jar', ranklib_location + 'RankLib-2.12.jar']\n",
    "        self.normalization = normalization\n",
    "        \n",
    "#     def build(self, ir_tool_params):\n",
    "    def train(self, train_data_file):\n",
    "\n",
    "        toolkit_parameters = [\n",
    "                                *self.ranker_command, # * to unpack list elements\n",
    "                                '-train',\n",
    "                                train_data_file,\n",
    "                                *self.normalization,\n",
    "                                *self.params\n",
    "                            ] \n",
    "        \n",
    "        print(toolkit_parameters)\n",
    "        with open(self.log_file, 'wt') as rf:\n",
    "            proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=rf, stderr=subprocess.STDOUT, shell=False)\n",
    "#         proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "            \n",
    "        (out, err)= proc.communicate()\n",
    "#         print(out.decode('utf-8').splitlines())\n",
    "#         print(out)\n",
    "#         print(err)\n",
    "        print('Model saved: ', self.params[-1:][0])\n",
    "            \n",
    "  \n",
    "\n",
    "    def gen_run_file(self, test_data_file, run_file):\n",
    "        pre_run_file = run_file.replace('run_', 'pre_run_', 1)\n",
    "        toolkit_parameters = [\n",
    "                                *self.ranker_command, # * to unpack list elements\n",
    "                                '-load',\n",
    "                                self.params[-1:][0],\n",
    "                                *self.normalization,\n",
    "                                '-rank',\n",
    "                                test_data_file,\n",
    "                                '-indri',\n",
    "                                pre_run_file     \n",
    "                            ] \n",
    "        \n",
    "        print(toolkit_parameters)\n",
    "        with open(self.log_file, 'at') as rf:\n",
    "            proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=rf, stderr=subprocess.STDOUT, shell=False)\n",
    "#         proc = subprocess.Popen(toolkit_parameters,stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False)\n",
    "            \n",
    "        (out, err)= proc.communicate()\n",
    "#         print(out.decode('utf-8').splitlines())\n",
    "#         print(out)\n",
    "#         print(err)\n",
    "\n",
    "        \n",
    "        generate_run_file(pre_run_file, run_file)\n",
    "        \n",
    "        print('Run model saved: ', run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bioasq_dir/bioasq_lmart_enabled_features\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Options and variables\n",
    "#     dataset = sys.argv[1] # 'bioasq'\n",
    "#     workdir = './' + dataset + '_dir/'\n",
    "#     data_split = sys.argv[2] # 'test'\n",
    "\n",
    "    dataset = 'bioasq'\n",
    "    workdir = './' + dataset + '_dir/'\n",
    "    data_split =  'train'\n",
    "    k_fold = 's1' \n",
    "    ranklib_location = '../../../ranklib/'\n",
    "    \n",
    "#     train_data_file = './bioasq_dir/bioasq.trai_features_reduced'\n",
    "    train_data_file = './bioasq_dir/bioasq.trai_features'\n",
    "#     val_data_file = './bioasq_dir/bioasq.dev_features_reduced'\n",
    "    val_data_file = './bioasq_dir/bioasq.dev_features'\n",
    "#     test_data_file = './bioasq_dir/bioasq.test_features_reduced'\n",
    "    test_data_file = './bioasq_dir/bioasq.test_features'\n",
    "    \n",
    "    l2r_model = '_lmart_'\n",
    "    \n",
    "    save_model_file = workdir + dataset + l2r_model\n",
    "    \n",
    "    pre_run_file = workdir + 'pre_run_' + dataset + l2r_model\n",
    "    \n",
    "    run_file = workdir + 'run_' + dataset + l2r_model\n",
    "    \n",
    "    enabled_features_file = workdir + dataset + l2r_model + 'enabled_features'\n",
    "    \n",
    "    print(enabled_features_file)\n",
    "    # Train L2R model: LambdaMART\n",
    "    # Parameters \n",
    "    \n",
    "    n_leaves = '10'\n",
    "    learning_rate = '0.1'\n",
    "    n_trees = '1000'\n",
    "    hpo_params = [n_leaves, learning_rate, n_trees]\n",
    "    metric2t = 'MAP' # 'MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)'\n",
    "    \n",
    "    ranker_type = '6' # LambdaMART\n",
    "    \n",
    "    # normalization: Feature Engineering?\n",
    "    norm_params = ['-norm', 'zscore'] # 'sum', 'zscore', 'linear'\n",
    "    \n",
    "    l2r_params = [\n",
    "        '-validate',\n",
    "        val_data_file,\n",
    "        '-ranker',\n",
    "        ranker_type,\n",
    "        '-metric2t',\n",
    "        metric2t,\n",
    "        '-leaf', \n",
    "        hpo_params[0],\n",
    "        '-shrinkage',\n",
    "        hpo_params[1],\n",
    "        '-tree', # Fix: is this necessary according to original paper?\n",
    "        hpo_params[2], \n",
    "        '-feature',\n",
    "        enabled_features_file,   \n",
    "        '-save',\n",
    "        save_model_file   \n",
    "    ]\n",
    "    \n",
    "    # Run train\n",
    "    \n",
    "    lmart_model = L2Ranker(ranklib_location, l2r_params)\n",
    "#     lmart_model = L2Ranker(ranklib_location, l2r_paramsm, norm_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['java', '-jar', '../../../ranklib/RankLib-2.12.jar', '-train', './bioasq_dir/bioasq.trai_features', '-validate', './bioasq_dir/bioasq.dev_features', '-ranker', '6', '-metric2t', 'MAP', '-leaf', '10', '-shrinkage', '0.1', '-tree', '1000', '-feature', './bioasq_dir/bioasq_lmart_enabled_features', '-save', './bioasq_dir/bioasq_lmart_']\n",
      "Model saved:  ./bioasq_dir/bioasq_lmart_\n"
     ]
    }
   ],
   "source": [
    "    lmart_model.train(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['java', '-jar', '../../../ranklib/RankLib-2.12.jar', '-load', './bioasq_dir/bioasq_lmart_', '-rank', './bioasq_dir/bioasq.test_features', '-indri', './bioasq_dir/pre_run_bioasq_lmart_']\n",
      "<class 'list'>\n",
      "Run model saved:  ./bioasq_dir/run_bioasq_lmart_\n"
     ]
    }
   ],
   "source": [
    "    lmart_model.gen_run_file(test_data_file, run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../eval/trec_eval', '-m', 'map', '-m', 'P.20', '-m', 'ndcg_cut.20', './bioasq_dir/bioasq.test_qrels', './bioasq_dir/run_bioasq_lmart_']\n",
      "map                   \tall\t0.3043\n",
      "P_20                  \tall\t0.1646\n",
      "ndcg_cut_20           \tall\t0.3609\n",
      "\n",
      "Run error:  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ok'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    trec_eval_command = '../../eval/trec_eval'\n",
    "    qrels_file = './bioasq_dir/bioasq.test_qrels'\n",
    "    eval(trec_eval_command, qrels_file, run_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
