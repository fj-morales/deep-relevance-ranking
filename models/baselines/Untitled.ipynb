{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_pickle_file = '../../robust04_data/IDF.pkl'\n",
    "idf = pickle.load( open(idf_pickle_file, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: 80-month\n",
      "Preprocessed text: 80 month\n",
      "Tokens: ['80', 'month']\n"
     ]
    }
   ],
   "source": [
    "clean = lambda t: re.sub('[,?;*!%^&_+():-\\[\\]{}]', ' ', t.replace('\"', ' ').replace('/', ' ').replace('\\\\', ' ').replace(\"'\", ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('-', ' ').replace('.', '').replace('&hyph;', ' ').replace('&blank;', ' ').strip().lower())\n",
    "\n",
    "# To tokenize a text field, first preprocess it using the \"clean\" lambda function, then tokenize preproceesed text with nltk tokenizer.\n",
    "\n",
    "raw_text = '80-month'\n",
    "preprocessed_text = clean(raw_text)\n",
    "tokens = nltk.word_tokenize(preprocessed_text)\n",
    "\n",
    "print('Raw text: {0}'.format(raw_text))\n",
    "print('Preprocessed text: {0}'.format(preprocessed_text))\n",
    "print('Tokens: {0}'.format(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.926524998039284"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ir_lmart_config.json') as j_file:\n",
    "    lmart_config = json.load(j_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h_params': {'n_trees': {'max': '50', 'step': '1', 'min': '1'},\n",
       "  'n_leaves': {'max': '50', 'step': '1', 'min': '1'},\n",
       "  'shrinkage': {'max': '1', 'step': '0.1', 'min': '0.1'}},\n",
       " 'budget': {'name': 'early_stop', 'max': '100', 'min': '10'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmart_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for key, value in idf.items():\n",
    "#     if i > 100:\n",
    "#         break\n",
    "#     print(key,value)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_terms = idf.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_keys = [key for key in idf.keys()]\n",
    "# dic_keys = dic_keys[9000000:10000000]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_keys = sorted(dic_keys, key=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmed = [stemmer.stem(word) for word in dic_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "careerist\n",
      "over-looked\n"
     ]
    }
   ],
   "source": [
    "stemmed = []\n",
    "\n",
    "for word in dic_keys:\n",
    "    if len(stemmed)%500000 == 0:\n",
    "        print(word)\n",
    "    stemmed.append(stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_stemmed = set(stemmed)\n",
    "len(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235800"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408-727-6116\n",
      "thurza\n",
      "swensonsa\n",
      "789420019\n",
      "hochdeutsch\n",
      "lien\n",
      "ยง4301a-f\n",
      "non-south\n",
      "|afflower-se\n",
      "archcliff\n",
      "djazzara\n",
      "purple-r\n",
      "29466\n",
      "elsberg\n",
      "23260\n",
      "433964\n",
      "ยง401\n",
      "40613b\n",
      "khanka\n",
      "oboroneksport\n",
      "guarantee-schem\n",
      "sedey\n",
      "648-5035\n",
      "four-lett\n",
      "jasnogora\n",
      "84532\n",
      "ยง2101\n",
      "05827\n",
      "streetclark\n",
      "1656p\n",
      "tuten\n",
      "bloodorgan\n",
      "selfhood\n",
      "all-compatriot\n",
      "abu-shariah\n",
      "walla\n",
      "|mileag\n",
      "219012580\n",
      "4695m\n",
      "fellow-profession\n",
      "kbal\n",
      "rose-johnson\n",
      "mathal\n",
      "a-|el\n",
      "flra\n",
      "fr29770\n",
      "tsaritsino\n",
      "petersburg-lvov\n",
      "makshanoff\n",
      "z113\n",
      "pespi-cola\n",
      "hasselt\n",
      "stock-split\n",
      "25099\n",
      "al-tawq\n",
      "95824\n",
      "12511\n",
      "7000-9000\n",
      "heartguide-approv\n",
      "pa0406032694\n",
      "unzon\n",
      "vrbovik\n",
      "macenro\n",
      "y715bn\n",
      "211453\n",
      "midsent\n",
      "1150-square-foot\n",
      "yorkpuerto\n",
      "hyong-chin\n",
      "010394b\n",
      "chickelero\n",
      "dubuch\n",
      "enounc\n",
      "reenforc\n",
      "sikh\n",
      "over-tir\n",
      "events-monitor\n",
      "brittenbroadhurst\n",
      "ambarsumov\n",
      "172627\n",
      "1051receipt\n",
      "122500\n",
      "3592387\n",
      "renaudin\n",
      "reform1\n",
      "ex-drive-in\n",
      "tyoplyy\n",
      "angioplastygreg\n",
      "kankahi\n",
      "ยง5902a2\n",
      "less-regul\n",
      "548-8755\n",
      "islom\n",
      "27477\n",
      "80-month\n",
      "4230stack\n",
      "9211\n",
      "fl3102\n",
      "broll-tertian\n",
      "368885\n",
      "gloeckner\n"
     ]
    }
   ],
   "source": [
    "for i,value in enumerate(unique_stemmed):\n",
    "    if i > 100: break\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ofmicrobes' in unique_stemmed:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = './original_vocab.txt'\n",
    "with open(save_file, 'wt', encoding='utf-8') as voc_f:\n",
    "     for i,item in enumerate(unique_stemmed):\n",
    "        voc_f.write(item + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
